# ğŸ§  Feedforward Neural Network from Scratch

This repository contains a Feedforward Neural Network (FFNN) built **from scratch** using Python and NumPy. The project was developed as part of **Tugas Besar 1** for the **IF3270 Machine Learning** course at Institut Teknologi Bandung.

## ğŸ“Œ Features

- âœ… Fully customizable neural network architecture
- âœ… Supports various activation functions:
  - Linear
  - ReLU
  - Sigmoid
  - Tanh
  - Softmax
- âœ… Multiple loss functions:
  - Mean Squared Error (MSE)
  - Binary Cross Entropy
  - Categorical Cross Entropy
- âœ… Weight initialization methods:
  - Zero Initialization
  - Random Uniform
  - Random Normal
- âœ… L1 and L2 Regularization
- âœ… Batch Gradient Descent
- âœ… Training/validation visualization (loss, weight/gradient distributions)
- âœ… Model saving and loading
- âœ… Evaluation and comparison with `sklearn`'s MLP

## ğŸ§ª Experiments

The network is tested on the **MNIST** dataset using `fetch_openml`. Performance and training insights are documented in the report.

Visualizations include:
- Network structure with weight and gradient flow
- Loss curve per epoch
- Distribution plots of weights and gradients per layer


## âš™ï¸ Setup and Run the Program

1. **Clone repository:**
```bash
git clone https://github.com/username/nama-repo.git](https://github.com/fauzanazz/Tubess-1-IF3270-PembelajaranMesin.git 
```
2. **Running the program**
```bash
python main.py
```
or run the ```simple.ipynb``` 
3. **Installing all dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Contributors
| Nama                   | NIM         | Contribution                                                                   |
|------------------------|-------------|--------------------------------------------------------------------------------|
| Auralea Alvinia S      | 13522148    | - Visualizing structure graph, weight distribution, gradient distribution      | 
|                        |             | - Input layer                                                                  |
| M. Fauzan Azhim        | 13522153    | - Regularization, normalization, activation function, loss function            |
|                        |             | - Back propagation, forward propagation                                        |
| Pradipta Rafa Mahesa   | 13522162    | - Creating safe and load                                                       |
|                        |             | - Weight init                                                                  |
